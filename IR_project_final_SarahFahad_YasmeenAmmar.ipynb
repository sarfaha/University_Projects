{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section : 52S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course name and number : \n",
    "Information Retrieval (DS321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project title :\n",
    "What is Data science ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group members :\n",
    "\n",
    "Sarah Fahad Alotaibi                        \n",
    "443007420\n",
    "\n",
    "Yasmeen Ammar Almutairi                    \n",
    "443007424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief description and goal of analysis:\n",
    "The goal of building an information retrieval (IR) project is to develop system and algorithms that efficiently and effectively retrieve relevant information from a large collection of data based on user queries or information needs. The primary objectives of our information retrieval project, which the query here is \"what is data science \"and the system we built should retrive the relevent document among the 3 documents we provide to the system ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The proposed corpus and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "HH5KwbrQQljb"
   },
   "outputs": [],
   "source": [
    "Doc1 = \"\"\" Data science combines math and statistics , specialized programming , advanced analytics , These insights can be used to guide decision making and strategic planning \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "_8zoTtxsRLQR"
   },
   "outputs": [],
   "source": [
    "Doc2 = \"\"\" Machine learning with specific subject matter expertise to uncover actionable , insights hidden in an organization data \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "GZjgsx4_ROCh"
   },
   "outputs": [],
   "source": [
    "Doc3= \"\"\" The accelerating volume of data sources, and subsequently data , has made data science is one of the fastest growing field across every industry \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "qmcx89pDRSMR"
   },
   "outputs": [],
   "source": [
    "Q =\"\"\"What is Data science?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "The preprocessing process: its preparation and preprocessing  methods, this procedure starts with taking an input of raw text and return cleansed tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting to lowercase : \n",
    "Change the upper case words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "OR_Ubh3IRTrS",
    "outputId": "346c6b28-6dd3-4a8d-f590-ba2dbeb375b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' data science combines math and statistics , specialized programming , advanced analytics , these insights can be used to guide decision making and strategic planning '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to lowercase using a function \n",
    "Doc1 = Doc1.lower()\n",
    "Doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J3TRAdh9ReCL",
    "outputId": "d7332e6b-4fba-4694-c97f-29d9c5bd2c4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machine learning with specific subject matter expertise to uncover actionable , insights hidden in an organization data '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc2 = Doc2.lower()\n",
    "Doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aHKQCR_ERkBw",
    "outputId": "d303803d-d2c0-461b-a678-2e3593c38ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the accelerating volume of data sources, and subsequently data , has made data science is one of the fastest growing field across every industry '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc3 = Doc3.lower()\n",
    "Doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "FJCaGA_oRop1"
   },
   "outputs": [],
   "source": [
    "#Using  the library String to use  a method in this library to remove punctuation\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "YIacHXPyRt48",
    "outputId": "bdfaa360-2acd-4e24-ff73-c0ad44604712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' data science combines math and statistics  specialized programming  advanced analytics  these insights can be used to guide decision making and strategic planning '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the punctuatuon from documents \n",
    "Doc1 = Doc1.translate(str.maketrans(\"\", \"\",string.punctuation))\n",
    "Doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GW4mKDisR6E3",
    "outputId": "8b32abf7-ad6a-4c25-8d73-6f19873feb65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machine learning with specific subject matter expertise to uncover actionable  insights hidden in an organization data '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc2 = Doc2.translate(str.maketrans(\"\", \"\",string.punctuation))\n",
    "Doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t9wIw1SiSFUl",
    "outputId": "802f8de7-9767-4047-d2c0-79f463957468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the accelerating volume of data sources and subsequently data  has made data science is one of the fastest growing field across every industry '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc3 = Doc3.translate(str.maketrans(\"\", \"\",string.punctuation))\n",
    "Doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing is the process of breaking down a text into individual units, called tokens. In the context of natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdD3HitbSKv8",
    "outputId": "7d6ac7ff-5b39-404c-c150-08c147140351"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the library nltk which is The Natural Language Toolkit apply preprocessing \n",
    "#(NLTK provides a wide range of text processing utilities, including tokenization, stemming, lemmatization)\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ciIWw5A4ST92"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize #Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bKJcUwPTTJN",
    "outputId": "027f1d80-9909-462e-8ec7-2925a0182ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'science',\n",
       " 'combines',\n",
       " 'math',\n",
       " 'and',\n",
       " 'statistics',\n",
       " 'specialized',\n",
       " 'programming',\n",
       " 'advanced',\n",
       " 'analytics',\n",
       " 'these',\n",
       " 'insights',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'guide',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'and',\n",
       " 'strategic',\n",
       " 'planning']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turning the documents into tokens \n",
    "tokens1= nltk.word_tokenize(Doc1)\n",
    "tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xAklwzYTZCl",
    "outputId": "8e63d989-767e-4233-b6da-5b60de21371b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'with',\n",
       " 'specific',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'expertise',\n",
       " 'to',\n",
       " 'uncover',\n",
       " 'actionable',\n",
       " 'insights',\n",
       " 'hidden',\n",
       " 'in',\n",
       " 'an',\n",
       " 'organization',\n",
       " 'data']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2= nltk.word_tokenize(Doc2)\n",
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdpuECduTgVm",
    "outputId": "390d6587-5cb5-44af-d044-81a33e6febab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'accelerating',\n",
       " 'volume',\n",
       " 'of',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'and',\n",
       " 'subsequently',\n",
       " 'data',\n",
       " 'has',\n",
       " 'made',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fastest',\n",
       " 'growing',\n",
       " 'field',\n",
       " 'across',\n",
       " 'every',\n",
       " 'industry']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens3= nltk.word_tokenize(Doc3)\n",
    "tokens3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words\n",
    "Stop Words pre-processing:  to drop frequent used words, which add no value to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "4hzeOqSYTnH7"
   },
   "outputs": [],
   "source": [
    "# Useing stop words so we can Improve Search Accuracy\n",
    "from nltk.corpus import stopwords #stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmLbKIEcTuUi",
    "outputId": "da6e3750-3d87-4fe2-fe90-5f08b84c2d2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6D_uY73eTxip",
    "outputId": "46f1a0d0-2179-4d00-cdee-7dc1f620f4ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stop=set(stopwords.words('english'))\n",
    "english_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-woGg7PgT0oe",
    "outputId": "a12b3a4b-348a-47c5-a3d8-f6a5f4a51636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'math', 'guide', 'strategic', 'programming', 'science', 'insights', 'used', 'planning', 'data', 'making', 'combines', 'statistics', 'decision', 'advanced', 'analytics', 'specialized'}\n"
     ]
    }
   ],
   "source": [
    "# removing stop words from document one \n",
    "filtered_words1=[word for word in tokens1 if word not in stopwords.words('english')]\n",
    "filtered_words1_set=set(filtered_words1)\n",
    "print(filtered_words1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t55VM4jUJ1y",
    "outputId": "a67a7185-95fe-49f7-c726-a4a77496a4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject', 'organization', 'insights', 'specific', 'expertise', 'matter', 'actionable', 'data', 'hidden', 'uncover', 'learning', 'machine'}\n"
     ]
    }
   ],
   "source": [
    "# removing stop words from document two\n",
    "filtered_words2=[word for word in tokens2 if word not in stopwords.words('english')]\n",
    "filtered_words2_set=set(filtered_words2)\n",
    "print(filtered_words2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaSu7LeqUSM7",
    "outputId": "e7e8cc63-2ff4-4ccf-c71a-b0730770fd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelerating', 'science', 'one', 'subsequently', 'growing', 'sources', 'field', 'data', 'made', 'every', 'fastest', 'industry', 'across', 'volume'}\n"
     ]
    }
   ],
   "source": [
    "# removing stop words from document three\n",
    "filtered_words3=[word for word in tokens3 if word not in stopwords.words('english')]\n",
    "filtered_words3_set=set(filtered_words3)\n",
    "print(filtered_words3_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Stemming is reducing words to their base or root form so we can improve the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "JKFBar1GUfXu"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer #Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "md-6qWtzUkBp"
   },
   "outputs": [],
   "source": [
    "word_stemmer = PorterStemmer() # this method perform stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'scienc', 'combin', 'math', 'statist', 'special', 'program', 'advanc', 'analyt', 'insight', 'use', 'guid', 'decis', 'make', 'strateg', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# apply stemming on the documents \n",
    "stemmed_words1 = [word_stemmer.stem(word) for word in filtered_words1]\n",
    "print(stemmed_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machin', 'learn', 'specif', 'subject', 'matter', 'expertis', 'uncov', 'action', 'insight', 'hidden', 'organ', 'data']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words2 = [word_stemmer.stem(word) for word in filtered_words2]\n",
    "print(stemmed_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceler', 'volum', 'data', 'sourc', 'subsequ', 'data', 'made', 'data', 'scienc', 'one', 'fastest', 'grow', 'field', 'across', 'everi', 'industri']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words3 = [word_stemmer.stem(word) for word in filtered_words3]\n",
    "print(stemmed_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oytm7ztqr0jZ",
    "outputId": "915b12b8-7c2e-4f38-8e6e-8d76e247b87c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'is', 'Data', 'science?']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spliting the query to improve the results \n",
    "Q_words = Q.split(' ')\n",
    "Q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M51FWb8btLMz",
    "outputId": "9995e6cc-43e0-483f-c6ee-d5c79ac0b8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'data', 'science?']\n"
     ]
    }
   ],
   "source": [
    "#apply stemming on the query for calculating the TF-IDF \n",
    "stemmed_wordsQ = [word_stemmer.stem(word) for word in Q_words]\n",
    "print(stemmed_wordsQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency (TF)\n",
    "Term frequency is the measurement of how frequently a term occurs within a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "EOvbvwk9VEwa"
   },
   "outputs": [],
   "source": [
    "#compining all the documents so we can calculate the term frequency and accurate values \n",
    "uniqueWords = set(stemmed_words1).union(set(stemmed_words2)).union(set(stemmed_words3))\n",
    "uniqueWordQ = set(stemmed_wordsQ) #  calculate the term frequency for the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d02qsE4NVc5c",
    "outputId": "ac8ed5b0-0b83-4542-b75b-604b65658cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject', 'plan', 'fastest', 'across', 'acceler', 'machin', 'math', 'action', 'statist', 'learn', 'one', 'specif', 'grow', 'advanc', 'data', 'guid', 'subsequ', 'uncov', 'combin', 'special', 'matter', 'make', 'organ', 'field', 'made', 'everi', 'hidden', 'industri', 'volum', 'sourc', 'expertis', 'use', 'insight', 'program', 'analyt', 'strateg', 'decis', 'scienc'}\n",
      "Unique Word Question {'data', 'is', 'science?', 'what'}\n"
     ]
    }
   ],
   "source": [
    "print(uniqueWords)\n",
    "print(f'Unique Word Question {uniqueWordQ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "DtZ2NA2bXVoJ"
   },
   "outputs": [],
   "source": [
    "num_of_word1=dict.fromkeys(uniqueWords,0)\n",
    "for word in stemmed_words1:\n",
    "  num_of_word1[word]+=1\n",
    "num_of_word2=dict.fromkeys(uniqueWords,0)\n",
    "for word in stemmed_words2:\n",
    "  num_of_word2[word]+=1\n",
    "num_of_word3=dict.fromkeys(uniqueWords,0)\n",
    "for word in stemmed_words3:\n",
    "  num_of_word3[word]+=1\n",
    "num_of_wordQ=dict.fromkeys(uniqueWordQ,0)\n",
    "for word in stemmed_wordsQ:\n",
    "  num_of_wordQ[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91IWVETMaP4Q",
    "outputId": "ca0a3f8f-ac6f-4691-a33c-fbc1796b921b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 0, 'plan': 1, 'fastest': 0, 'across': 0, 'acceler': 0, 'machin': 0, 'math': 1, 'action': 0, 'statist': 1, 'learn': 0, 'one': 0, 'specif': 0, 'grow': 0, 'advanc': 1, 'data': 1, 'guid': 1, 'subsequ': 0, 'uncov': 0, 'combin': 1, 'special': 1, 'matter': 0, 'make': 1, 'organ': 0, 'field': 0, 'made': 0, 'everi': 0, 'hidden': 0, 'industri': 0, 'volum': 0, 'sourc': 0, 'expertis': 0, 'use': 1, 'insight': 1, 'program': 1, 'analyt': 1, 'strateg': 1, 'decis': 1, 'scienc': 1}\n"
     ]
    }
   ],
   "source": [
    "#TF of document one \n",
    "print(num_of_word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 1, 'plan': 0, 'fastest': 0, 'across': 0, 'acceler': 0, 'machin': 1, 'math': 0, 'action': 1, 'statist': 0, 'learn': 1, 'one': 0, 'specif': 1, 'grow': 0, 'advanc': 0, 'data': 1, 'guid': 0, 'subsequ': 0, 'uncov': 1, 'combin': 0, 'special': 0, 'matter': 1, 'make': 0, 'organ': 1, 'field': 0, 'made': 0, 'everi': 0, 'hidden': 1, 'industri': 0, 'volum': 0, 'sourc': 0, 'expertis': 1, 'use': 0, 'insight': 1, 'program': 0, 'analyt': 0, 'strateg': 0, 'decis': 0, 'scienc': 0}\n"
     ]
    }
   ],
   "source": [
    "#TF of document two\n",
    "print(num_of_word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 0, 'plan': 0, 'fastest': 1, 'across': 1, 'acceler': 1, 'machin': 0, 'math': 0, 'action': 0, 'statist': 0, 'learn': 0, 'one': 1, 'specif': 0, 'grow': 1, 'advanc': 0, 'data': 3, 'guid': 0, 'subsequ': 1, 'uncov': 0, 'combin': 0, 'special': 0, 'matter': 0, 'make': 0, 'organ': 0, 'field': 1, 'made': 1, 'everi': 1, 'hidden': 0, 'industri': 1, 'volum': 1, 'sourc': 1, 'expertis': 0, 'use': 0, 'insight': 0, 'program': 0, 'analyt': 0, 'strateg': 0, 'decis': 0, 'scienc': 1}\n"
     ]
    }
   ],
   "source": [
    "#TF of document three\n",
    "print(num_of_word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': 1, 'is': 1, 'science?': 1, 'what': 1}\n"
     ]
    }
   ],
   "source": [
    "#TF of the query \n",
    "print(num_of_wordQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "W-rKOTwDTcZp",
    "outputId": "9e9a3ff4-df4e-4b84-ed85-55fcb1177ef8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>plan</th>\n",
       "      <th>fastest</th>\n",
       "      <th>across</th>\n",
       "      <th>acceler</th>\n",
       "      <th>machin</th>\n",
       "      <th>math</th>\n",
       "      <th>action</th>\n",
       "      <th>statist</th>\n",
       "      <th>learn</th>\n",
       "      <th>...</th>\n",
       "      <th>volum</th>\n",
       "      <th>sourc</th>\n",
       "      <th>expertis</th>\n",
       "      <th>use</th>\n",
       "      <th>insight</th>\n",
       "      <th>program</th>\n",
       "      <th>analyt</th>\n",
       "      <th>strateg</th>\n",
       "      <th>decis</th>\n",
       "      <th>scienc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  plan  fastest  across  acceler  machin  math  action  statist  \\\n",
       "0        0     1        0       0        0       0     1       0        1   \n",
       "1        1     0        0       0        0       1     0       1        0   \n",
       "2        0     0        1       1        1       0     0       0        0   \n",
       "\n",
       "   learn  ...  volum  sourc  expertis  use  insight  program  analyt  strateg  \\\n",
       "0      0  ...      0      0         0    1        1        1       1        1   \n",
       "1      1  ...      0      0         1    0        1        0       0        0   \n",
       "2      0  ...      1      1         0    0        0        0       0        0   \n",
       "\n",
       "   decis  scienc  \n",
       "0      1       1  \n",
       "1      0       0  \n",
       "2      0       1  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to format the results and make them look readable \n",
    "import pandas as pd\n",
    "pd.DataFrame([num_of_word1,num_of_word2,num_of_word3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>is</th>\n",
       "      <th>science?</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  is  science?  what\n",
       "0     1   1         1     1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([num_of_wordQ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "BGhqvcR7b4Yb"
   },
   "outputs": [],
   "source": [
    "#TF, this method calculate the term frequency \n",
    "def computeTF(word_dict,list_of_word):\n",
    "  TF_Dict ={}\n",
    "  word_count = len(list_of_word)\n",
    "  # you just pass the word with [0] => And you must use [word]\n",
    "  for word,count in word_dict.items():\n",
    "    TF_Dict[word] = count / float(word_count)\n",
    "  return TF_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPweGip4dtcI",
    "outputId": "03f37153-d020-4684-95b3-ad929a12eeff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 0.0,\n",
       " 'plan': 0.0625,\n",
       " 'fastest': 0.0,\n",
       " 'across': 0.0,\n",
       " 'acceler': 0.0,\n",
       " 'machin': 0.0,\n",
       " 'math': 0.0625,\n",
       " 'action': 0.0,\n",
       " 'statist': 0.0625,\n",
       " 'learn': 0.0,\n",
       " 'one': 0.0,\n",
       " 'specif': 0.0,\n",
       " 'grow': 0.0,\n",
       " 'advanc': 0.0625,\n",
       " 'data': 0.0625,\n",
       " 'guid': 0.0625,\n",
       " 'subsequ': 0.0,\n",
       " 'uncov': 0.0,\n",
       " 'combin': 0.0625,\n",
       " 'special': 0.0625,\n",
       " 'matter': 0.0,\n",
       " 'make': 0.0625,\n",
       " 'organ': 0.0,\n",
       " 'field': 0.0,\n",
       " 'made': 0.0,\n",
       " 'everi': 0.0,\n",
       " 'hidden': 0.0,\n",
       " 'industri': 0.0,\n",
       " 'volum': 0.0,\n",
       " 'sourc': 0.0,\n",
       " 'expertis': 0.0,\n",
       " 'use': 0.0625,\n",
       " 'insight': 0.0625,\n",
       " 'program': 0.0625,\n",
       " 'analyt': 0.0625,\n",
       " 'strateg': 0.0625,\n",
       " 'decis': 0.0625,\n",
       " 'scienc': 0.0625}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the method that calculate the term frequency for document one \n",
    "TF_Doc1 = computeTF(num_of_word1,stemmed_words1)\n",
    "TF_Doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYriCGv5gB3O",
    "outputId": "8bc284d8-cb55-44bc-8947-a9bd46cd2493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 0.08333333333333333,\n",
       " 'plan': 0.0,\n",
       " 'fastest': 0.0,\n",
       " 'across': 0.0,\n",
       " 'acceler': 0.0,\n",
       " 'machin': 0.08333333333333333,\n",
       " 'math': 0.0,\n",
       " 'action': 0.08333333333333333,\n",
       " 'statist': 0.0,\n",
       " 'learn': 0.08333333333333333,\n",
       " 'one': 0.0,\n",
       " 'specif': 0.08333333333333333,\n",
       " 'grow': 0.0,\n",
       " 'advanc': 0.0,\n",
       " 'data': 0.08333333333333333,\n",
       " 'guid': 0.0,\n",
       " 'subsequ': 0.0,\n",
       " 'uncov': 0.08333333333333333,\n",
       " 'combin': 0.0,\n",
       " 'special': 0.0,\n",
       " 'matter': 0.08333333333333333,\n",
       " 'make': 0.0,\n",
       " 'organ': 0.08333333333333333,\n",
       " 'field': 0.0,\n",
       " 'made': 0.0,\n",
       " 'everi': 0.0,\n",
       " 'hidden': 0.08333333333333333,\n",
       " 'industri': 0.0,\n",
       " 'volum': 0.0,\n",
       " 'sourc': 0.0,\n",
       " 'expertis': 0.08333333333333333,\n",
       " 'use': 0.0,\n",
       " 'insight': 0.08333333333333333,\n",
       " 'program': 0.0,\n",
       " 'analyt': 0.0,\n",
       " 'strateg': 0.0,\n",
       " 'decis': 0.0,\n",
       " 'scienc': 0.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the method that calculate the term frequency for document two\n",
    "TF_Doc2 = computeTF(num_of_word2,stemmed_words2)\n",
    "TF_Doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zxlzr5kugIQF",
    "outputId": "2a5338f0-348c-49ca-be98-cd04ad7cc00f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 0.0,\n",
       " 'plan': 0.0,\n",
       " 'fastest': 0.0625,\n",
       " 'across': 0.0625,\n",
       " 'acceler': 0.0625,\n",
       " 'machin': 0.0,\n",
       " 'math': 0.0,\n",
       " 'action': 0.0,\n",
       " 'statist': 0.0,\n",
       " 'learn': 0.0,\n",
       " 'one': 0.0625,\n",
       " 'specif': 0.0,\n",
       " 'grow': 0.0625,\n",
       " 'advanc': 0.0,\n",
       " 'data': 0.1875,\n",
       " 'guid': 0.0,\n",
       " 'subsequ': 0.0625,\n",
       " 'uncov': 0.0,\n",
       " 'combin': 0.0,\n",
       " 'special': 0.0,\n",
       " 'matter': 0.0,\n",
       " 'make': 0.0,\n",
       " 'organ': 0.0,\n",
       " 'field': 0.0625,\n",
       " 'made': 0.0625,\n",
       " 'everi': 0.0625,\n",
       " 'hidden': 0.0,\n",
       " 'industri': 0.0625,\n",
       " 'volum': 0.0625,\n",
       " 'sourc': 0.0625,\n",
       " 'expertis': 0.0,\n",
       " 'use': 0.0,\n",
       " 'insight': 0.0,\n",
       " 'program': 0.0,\n",
       " 'analyt': 0.0,\n",
       " 'strateg': 0.0,\n",
       " 'decis': 0.0,\n",
       " 'scienc': 0.0625}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the method that calculate the term frequency for document three\n",
    "TF_Doc3 = computeTF(num_of_word3,stemmed_words3)\n",
    "TF_Doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 0.25, 'is': 0.25, 'science?': 0.25, 'what': 0.25}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the method that calculate the term frequency for the query \n",
    "TF_Q = computeTF(num_of_wordQ,stemmed_wordsQ)\n",
    "TF_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to calculate the term frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanc: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "analyt: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "combin: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "data: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "decis: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "guid: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "insight: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "make: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "math: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "plan: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "program: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "scienc: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "special: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "statist: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "strateg: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "use: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf_Doc1 = vectorizer.fit_transform(stemmed_words1)\n",
    "feature_names_Doc1 = vectorizer.get_feature_names()\n",
    "tf_dict_Doc1 = {}\n",
    "for term, index in zip(feature_names_Doc1, range(len(feature_names_Doc1))):\n",
    "    # Get the term frequency value for each document\n",
    "    tf_values = tf_Doc1[:, index].toarray().flatten()\n",
    "    tf_dict_Doc1[term] = tf_values\n",
    "for term, tf_values in tf_dict_Doc1.items():\n",
    "    print(f\"{term}: {tf_values}\")\n",
    "#[data,scienc,combin,math,statist,special,program,advanc,analyt,insight,use,guid,decis,make,strateg,plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "data: [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "expertis: [0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "hidden: [0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "insight: [0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "learn: [0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "machin: [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "matter: [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "organ: [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "specif: [0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "subject: [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "uncov: [0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf_Doc2 = vectorizer.fit_transform(stemmed_words2)\n",
    "feature_names_Doc2 = vectorizer.get_feature_names()\n",
    "tf_dict_Doc2 = {}\n",
    "for term, index in zip(feature_names_Doc2, range(len(feature_names_Doc2))):\n",
    "    # Get the term frequency value for each document\n",
    "    tf_values = tf_Doc2[:, index].toarray().flatten()\n",
    "    tf_dict_Doc2[term] = tf_values\n",
    "for term, tf_values in tf_dict_Doc2.items():\n",
    "    print(f\"{term}: {tf_values}\")\n",
    "#[machin,learn,specif,subject,matter,expertis,uncov,action,insight,hidden,organ,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceler: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "across: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "data: [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "everi: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "fastest: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "field: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "grow: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "industri: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "made: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "one: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "scienc: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "sourc: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "subsequ: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "volum: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf_Doc3 = vectorizer.fit_transform(stemmed_words3)\n",
    "feature_names_Doc3 = vectorizer.get_feature_names()\n",
    "tf_dict_Doc3 = {}\n",
    "for term, index in zip(feature_names_Doc3, range(len(feature_names_Doc3))):\n",
    "    # Get the term frequency value for each document\n",
    "    tf_values = tf_Doc3[:, index].toarray().flatten()\n",
    "    tf_dict_Doc3[term] = tf_values\n",
    "for term, tf_values in tf_dict_Doc3.items():\n",
    "    print(f\"{term}: {tf_values}\")\n",
    "#[acceler,volum,data,sourc,subsequ,data,made,data,scienc,one,fastest,grow,field,across,everi,industri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [0 0 1 0]\n",
      "is: [0 1 0 0]\n",
      "science: [0 0 0 1]\n",
      "what: [1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf_Q = vectorizer.fit_transform(stemmed_wordsQ)\n",
    "feature_names_Q = vectorizer.get_feature_names()\n",
    "tf_dict_Q = {}\n",
    "for term, index in zip(feature_names_Q, range(len(feature_names_Q))):\n",
    "    # Get the term frequency value for each document\n",
    "    tf_values = tf_Q[:, index].toarray().flatten()\n",
    "    tf_dict_Q[term] = tf_values\n",
    "for term, tf_values in tf_dict_Q.items():\n",
    "    print(f\"{term}: {tf_values}\")\n",
    "#[what,is,data,science]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Document Frequency (IDF)\n",
    "Inverse Document Frequency (IDF) is a weight indicating how commonly a word is used. The more frequent its usage across documents, the lower its score. The lower the score, the less important the word becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "sOv1qnL0lrTy"
   },
   "outputs": [],
   "source": [
    "#IDF, this method calculate the inverse document frequency  \n",
    "def computeIDF(Documents):\n",
    "  import math\n",
    "  N = len(Documents)\n",
    "  IDF_Dict = dict.fromkeys(Documents[0].keys(),0)\n",
    "  for Document in Documents:\n",
    "    for word,val in Document.items():\n",
    "      if val>0:\n",
    "        IDF_Dict[word]+=1\n",
    "  for word,val in IDF_Dict.items():\n",
    "    IDF_Dict[word] = math.log (N /float(val))\n",
    "  return IDF_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Isg1TMrrnepJ",
    "outputId": "3383bdf4-e4b1-4a5f-b243-65b23ef49349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 1.0986122886681098,\n",
       " 'plan': 1.0986122886681098,\n",
       " 'fastest': 1.0986122886681098,\n",
       " 'across': 1.0986122886681098,\n",
       " 'acceler': 1.0986122886681098,\n",
       " 'machin': 1.0986122886681098,\n",
       " 'math': 1.0986122886681098,\n",
       " 'action': 1.0986122886681098,\n",
       " 'statist': 1.0986122886681098,\n",
       " 'learn': 1.0986122886681098,\n",
       " 'one': 1.0986122886681098,\n",
       " 'specif': 1.0986122886681098,\n",
       " 'grow': 1.0986122886681098,\n",
       " 'advanc': 1.0986122886681098,\n",
       " 'data': 0.0,\n",
       " 'guid': 1.0986122886681098,\n",
       " 'subsequ': 1.0986122886681098,\n",
       " 'uncov': 1.0986122886681098,\n",
       " 'combin': 1.0986122886681098,\n",
       " 'special': 1.0986122886681098,\n",
       " 'matter': 1.0986122886681098,\n",
       " 'make': 1.0986122886681098,\n",
       " 'organ': 1.0986122886681098,\n",
       " 'field': 1.0986122886681098,\n",
       " 'made': 1.0986122886681098,\n",
       " 'everi': 1.0986122886681098,\n",
       " 'hidden': 1.0986122886681098,\n",
       " 'industri': 1.0986122886681098,\n",
       " 'volum': 1.0986122886681098,\n",
       " 'sourc': 1.0986122886681098,\n",
       " 'expertis': 1.0986122886681098,\n",
       " 'use': 1.0986122886681098,\n",
       " 'insight': 0.4054651081081644,\n",
       " 'program': 1.0986122886681098,\n",
       " 'analyt': 1.0986122886681098,\n",
       " 'strateg': 1.0986122886681098,\n",
       " 'decis': 1.0986122886681098,\n",
       " 'scienc': 0.4054651081081644}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the method to calculate the inverse document frequency for the documents \n",
    "IDFs = computeIDF([num_of_word1,num_of_word2,num_of_word3])\n",
    "IDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF models\n",
    "TF-IDF stands for term frequency-inverse document frequency and it is a measure; TF-IDF(t,d,D) = tf(t, d) . idf (t,D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer#to calculate the tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25\n",
      "  0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "#calculate TF-IDF for document one \n",
    "Doc1_stem = [' '.join(stemmed_words1)]\n",
    "vectorizer_Doc1 = TfidfVectorizer()\n",
    "Doc1_TFidf = vectorizer_Doc1.fit_transform(Doc1_stem)\n",
    "print(Doc1_TFidf.toarray())\n",
    "#data,scienc,combin,math,statist,special,program,advanc,analyt,insight,use,guid,decis,make,strateg,plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28867513 0.28867513 0.28867513 0.28867513 0.28867513 0.28867513\n",
      "  0.28867513 0.28867513 0.28867513 0.28867513 0.28867513 0.28867513]]\n"
     ]
    }
   ],
   "source": [
    "#calculate TF-IDF for document two\n",
    "Doc2_stem = [' '.join(stemmed_words2)]\n",
    "vectorizer_Doc2 = TfidfVectorizer()\n",
    "Doc2_TFidf = vectorizer_Doc2.fit_transform(Doc2_stem)\n",
    "print(Doc2_TFidf.toarray())\n",
    "#[machin,learn,specif,subject,matter,expertis,uncov,action,insight,hidden,organ,data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21320072 0.21320072 0.63960215 0.21320072 0.21320072 0.21320072\n",
      "  0.21320072 0.21320072 0.21320072 0.21320072 0.21320072 0.21320072\n",
      "  0.21320072 0.21320072]]\n"
     ]
    }
   ],
   "source": [
    "#calculate TF-IDF for document three\n",
    "Doc3_stem = [' '.join(stemmed_words3)]\n",
    "vectorizer_Doc3 = TfidfVectorizer()\n",
    "Doc3_TFidf = vectorizer_Doc3.fit_transform(Doc3_stem)\n",
    "print(Doc3_TFidf.toarray())\n",
    "#[acceler,volum,data,sourc,subsequ,made,scienc,one,fastest,grow,field,across,everi,industri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5 0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#calculate TF-IDF for the query \n",
    "Q_stem = [' '.join(stemmed_wordsQ)]\n",
    "vectorizer_Q = TfidfVectorizer()\n",
    "Q_TFidf = vectorizer_Q.fit_transform(Q_stem)\n",
    "print(Q_TFidf.toarray())\n",
    "#[what,is,data,science]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the cosine similarity:\n",
    "Influence and relevancy of documents with user query is measured using cosine similarity under a vector space where set of documents is considered as a set of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the cosine similarity we used a library that exist so it can calculate it and rank the results \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "prepro_query = ' '.join(stemmed_wordsQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Doc1 and the query: 0.06865710564998491\n"
     ]
    }
   ],
   "source": [
    "#calculating the cosine similarity between document one and the query \n",
    "prepro_Doc1 = ' '.join(stemmed_words1)\n",
    "\n",
    "document1 = [prepro_Doc1, prepro_query]\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the documents\n",
    "tfidf_matrix= vectorizer.fit_transform(document1)\n",
    "\n",
    "# Calculate cosine similarity between Doc1 and the query\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "# Print the cosine similarity score\n",
    "print(f\"Cosine Similarity between Doc1 and the query: {cosine_similarities[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Doc2 and the query: 0.07970251181266945\n"
     ]
    }
   ],
   "source": [
    "#calculating the cosine similarity between document two and the query \n",
    "prepro_Doc2 = ' '.join(stemmed_words2)\n",
    "\n",
    "document2 = [prepro_Doc2, prepro_query]\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(document2)\n",
    "\n",
    "# Calculate cosine similarity between Doc1 and the query\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "# Print the cosine similarity score\n",
    "print(f\"Cosine Similarity between Doc2 and the query: {cosine_similarities[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Doc3 and the query: 0.19357302867354925\n"
     ]
    }
   ],
   "source": [
    "#calculating the cosine similarity between document three and the query \n",
    "prepro_Doc3 = ' '.join(stemmed_words3)\n",
    "\n",
    "document3 = [prepro_Doc3, prepro_query]\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(document3)\n",
    "\n",
    "# Calculate cosine similarity between Doc1 and the query\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "# Print the cosine similarity score\n",
    "print(f\"Cosine Similarity between Doc3 and the query: {cosine_similarities[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion (the rank of documents)\n",
    "In conclusion: after comparing each document with the query the result we got from calculating the cosine similarity and then ranking them in a descending order, so as the results show after ranking the documents, document three got the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranked Documents based on Cosine Similarity:\n",
    "\n",
    "Document 3: Cosine Similarity = 0.19357302867354925\n",
    "\n",
    "Document 2: Cosine Similarity = 0.07970251181266945\n",
    "\n",
    "Document 1: Cosine Similarity = 0.06865710564998491"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
